{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Landing vehicle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://mostaqbal.ae/wp-content/uploads/2019/07/india-launching-moon-mission-sunday-1200x630.jpg\" alt=\"Drawing\" style=\"height: 200px;\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from abc import ABCMeta, abstractmethod\n",
    "class environment:\n",
    " # RLGlue environment\n",
    "\n",
    "\n",
    "    __metaclass__ = ABCMeta\n",
    "\n",
    "    def __init__(self):\n",
    "        reward = None\n",
    "        observation = None\n",
    "        termination = None\n",
    "        self.reward_obs_term = (reward, observation, termination)\n",
    "\n",
    "    @abstractmethod\n",
    "    def env_init(self, env_info={}):\n",
    "\n",
    "\n",
    "    @abstractmethod\n",
    "    def env_start(self):\n",
    "\n",
    "    @abstractmethod\n",
    "    def env_step(self, action):\n",
    "    \n",
    "    @abstractmethod\n",
    "    def env_cleanup(self):\n",
    "\n",
    "    @abstractmethod\n",
    "    def env_message(self, message):\n",
    "\n",
    "class BaseAgent:\n",
    "\n",
    "    __metaclass__ = ABCMeta\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def agent_init(self, agent_info= {}):\n",
    "\n",
    "    @abstractmethod\n",
    "    def agent_start(self, observation):\n",
    " \n",
    "    @abstractmethod\n",
    "    def agent_step(self, reward, observation):\n",
    "      \n",
    "    @abstractmethod\n",
    "    def agent_end(self, reward):\n",
    "\n",
    "    @abstractmethod\n",
    "    def agent_cleanup(self):\n",
    "\n",
    "    @abstractmethod\n",
    "    def agent_message(self, message):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "#http://www.jmlr.org/papers/v10/tanner09a.html\n",
    "class RLGlue:\n",
    "\n",
    "\n",
    "    def __init__(self, env_class, agent_class):\n",
    "        self.environment = env_class()\n",
    "        self.agent = agent_class()\n",
    "\n",
    "        self.total_reward = None\n",
    "        self.last_action = None\n",
    "        self.num_steps = None\n",
    "        self.num_episodes = None\n",
    "\n",
    "    def rl_init(self, agent_init_info={}, env_init_info={}):\n",
    "        self.environment.env_init(env_init_info)\n",
    "        self.agent.agent_init(agent_init_info)\n",
    "\n",
    "        self.total_reward = 0.0\n",
    "        self.num_steps = 0\n",
    "        self.num_episodes = 0\n",
    "\n",
    "    def rl_start(self, agent_start_info={}, env_start_info={}):\n",
    "       \n",
    "        \n",
    "        self.total_reward = 0.0\n",
    "        self.num_steps = 1\n",
    "\n",
    "        last_state = self.environment.env_start()\n",
    "        self.last_action = self.agent.agent_start(last_state)\n",
    "\n",
    "        observation = (last_state, self.last_action)\n",
    "\n",
    "        return observation\n",
    "\n",
    "    def rl_agent_start(self, observation):\n",
    "\n",
    "        return self.agent.agent_start(observation)\n",
    "\n",
    "    def rl_agent_step(self, reward, observation):\n",
    "       \n",
    "        return self.agent.agent_step(reward, observation)\n",
    "\n",
    "    def rl_agent_end(self, reward):\n",
    "\n",
    "        self.agent.agent_end(reward)\n",
    "\n",
    "    def rl_env_start(self):\n",
    " \n",
    "        self.total_reward = 0.0\n",
    "        self.num_steps = 1\n",
    "\n",
    "        this_observation = self.environment.env_start()\n",
    "\n",
    "        return this_observation\n",
    "\n",
    "    def rl_env_step(self, action):\n",
    "\n",
    "        ro = self.environment.env_step(action)\n",
    "        (this_reward, _, terminal) = ro\n",
    "\n",
    "        self.total_reward += this_reward\n",
    "\n",
    "        if terminal:\n",
    "            self.num_episodes += 1\n",
    "        else:\n",
    "            self.num_steps += 1\n",
    "\n",
    "        return ro\n",
    "\n",
    "    def rl_step(self):\n",
    "\n",
    "        (reward, last_state, term) = self.environment.env_step(self.last_action)\n",
    "\n",
    "        self.total_reward += reward;\n",
    "\n",
    "        if term:\n",
    "            self.num_episodes += 1\n",
    "            self.agent.agent_end(reward)\n",
    "            roat = (reward, last_state, None, term)\n",
    "        else:\n",
    "            self.num_steps += 1\n",
    "            self.last_action = self.agent.agent_step(reward, last_state)\n",
    "            roat = (reward, last_state, self.last_action, term)\n",
    "\n",
    "        return roat\n",
    "\n",
    "    def rl_cleanup(self):\n",
    "        self.environment.env_cleanup()\n",
    "        self.agent.agent_cleanup()\n",
    "\n",
    "    def rl_agent_message(self, message):\n",
    "       \n",
    "\n",
    "        return self.agent.agent_message(message)\n",
    "\n",
    "    def rl_env_message(self, message):\n",
    "\n",
    "        return self.environment.env_message(message)\n",
    "\n",
    "    def rl_episode(self, max_steps_this_episode):\n",
    "\n",
    "        is_terminal = False\n",
    "\n",
    "        self.rl_start()\n",
    "\n",
    "        while (not is_terminal) and ((max_steps_this_episode == 0) or\n",
    "                                     (self.num_steps < max_steps_this_episode)):\n",
    "            rl_step_result = self.rl_step()\n",
    "            is_terminal = rl_step_result[3]\n",
    "\n",
    "        return is_terminal\n",
    "\n",
    "    def rl_return(self):\n",
    " \n",
    "        return self.total_reward\n",
    "\n",
    "    def rl_num_steps(self):\n",
    "\n",
    "        return self.num_steps\n",
    "\n",
    "    def rl_num_episodes(self):\n",
    "\n",
    "        return self.num_episodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "\n",
    "class Landingvehicle(environment):\n",
    "    def env_init(self, env_info={}):\n",
    "        \n",
    "        self.env = gym.make(\"LunarLander-v2\")\n",
    "        self.env.seed(0)\n",
    "\n",
    "    def env_start(self):\n",
    "      \n",
    "        reward = 0.0\n",
    "        observation = self.env.reset()\n",
    "        is_terminal = False\n",
    "                \n",
    "        self.reward_obs_term = (reward, observation, is_terminal)\n",
    "        \n",
    "        return self.reward_obs_term[1]\n",
    "        \n",
    "    def env_step(self, action):\n",
    "     \n",
    "\n",
    "        last_state = self.reward_obs_term[1]\n",
    "        current_state, reward, is_terminal, _ = self.env.step(action)\n",
    "        \n",
    "        self.reward_obs_term = (reward, current_state, is_terminal)\n",
    "        \n",
    "        return self.reward_obs_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "plt_legend_dict = {\"expected_sarsa_agent\": \"Expected SARSA with neural network\",\n",
    "                   \"random_agent\": \"Random\"}\n",
    "path_dict = {\"expected_sarsa_agent\": \"results/\",\n",
    "             \"random_agent\": \"./\"}\n",
    "\n",
    "plt_label_dict = {\"expected_sarsa_agent\": \"Sum of\\nreward\\nduring\\nepisode\"}\n",
    "\n",
    "\n",
    "\n",
    "# Function to plot result\n",
    "def plot_result(data_name_array):\n",
    "    plt_agent_sweeps = []\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(8,6))\n",
    "\n",
    "    \n",
    "    for data_name in data_name_array:\n",
    "        \n",
    "        # load data\n",
    "        filename = 'sum_reward_{}'.format(data_name).replace('.','')\n",
    "        sum_reward_data = np.load('{}/{}.npy'.format(path_dict[data_name], filename))\n",
    "\n",
    "        # smooth data\n",
    "        smoothed_sum_reward = smooth(data = sum_reward_data, k = 100)\n",
    "        \n",
    "        mean_smoothed_sum_reward = np.mean(smoothed_sum_reward, axis = 0)\n",
    "\n",
    "        plot_x_range = np.arange(0, mean_smoothed_sum_reward.shape[0])\n",
    "        graph_current_agent_sum_reward, = ax.plot(plot_x_range, mean_smoothed_sum_reward[:], label=plt_legend_dict[data_name])\n",
    "        plt_agent_sweeps.append(graph_current_agent_sum_reward)\n",
    "    \n",
    "    ax.legend(handles=plt_agent_sweeps, fontsize = 13)\n",
    "    ax.set_title(\"Learning Curve\", fontsize = 15)\n",
    "    ax.set_xlabel('Episodes', fontsize = 14)\n",
    "    ax.set_ylabel(plt_label_dict[data_name_array[0]], rotation=0, labelpad=40, fontsize = 14)\n",
    "    ax.set_ylim([-300, 300])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from collections import deque\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import os \n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Action-Value Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActionValueNetwork:\n",
    "    def __init__(self, network_config):\n",
    "        self.state_dim = network_config.get(\"state_dim\")\n",
    "        self.num_hidden_units = network_config.get(\"num_hidden_units\")\n",
    "        self.num_actions = network_config.get(\"num_actions\")\n",
    "        \n",
    "        self.rand_generator = np.random.RandomState(network_config.get(\"seed\"))\n",
    "        self.layer_sizes = [self.state_dim,self.num_hidden_units,self.num_actions ]\n",
    "        self.weights = [dict() for i in range(0, len(self.layer_sizes) - 1)]\n",
    "        for i in range(0, len(self.layer_sizes) - 1):\n",
    "            self.weights[i]['W'] = self.init_saxe(self.layer_sizes[i], self.layer_sizes[i + 1])\n",
    "            self.weights[i]['b'] = np.zeros((1, self.layer_sizes[i + 1]))\n",
    "    def get_action_values(self, s):\n",
    " \n",
    "        W0, b0 = self.weights[0]['W'], self.weights[0]['b']\n",
    "        psi = np.dot(s, W0) + b0\n",
    "        x = np.maximum(psi, 0)\n",
    "        \n",
    "        W1, b1 = self.weights[1]['W'], self.weights[1]['b']\n",
    "        q_vals = np.dot(x, W1) + b1\n",
    "\n",
    "        return q_vals\n",
    "    \n",
    "    def get_TD_update(self, s, delta_mat):\n",
    "  \n",
    "\n",
    "        W0, b0 = self.weights[0]['W'], self.weights[0]['b']\n",
    "        W1, b1 = self.weights[1]['W'], self.weights[1]['b']\n",
    "        \n",
    "        psi = np.dot(s, W0) + b0\n",
    "        x = np.maximum(psi, 0)\n",
    "        dx = (psi > 0).astype(float)\n",
    "\n",
    "      \n",
    "        td_update = [dict() for i in range(len(self.weights))]\n",
    "         \n",
    "        v = delta_mat\n",
    "        td_update[1]['W'] = np.dot(x.T, v) * 1. / s.shape[0]\n",
    "        td_update[1]['b'] = np.sum(v, axis=0, keepdims=True) * 1. / s.shape[0]\n",
    "        \n",
    "        v = np.dot(v, W1.T) * dx\n",
    "        td_update[0]['W'] = np.dot(s.T, v) * 1. / s.shape[0]\n",
    "        td_update[0]['b'] = np.sum(v, axis=0, keepdims=True) * 1. / s.shape[0]\n",
    "                \n",
    "        return td_update\n",
    "    \n",
    "   \n",
    "    def init_saxe(self, rows, cols):\n",
    "     \n",
    "        tensor = self.rand_generator.normal(0, 1, (rows, cols))\n",
    "        if rows < cols:\n",
    "            tensor = tensor.T\n",
    "        tensor, r = np.linalg.qr(tensor)\n",
    "        d = np.diag(r, 0)\n",
    "        ph = np.sign(d)\n",
    "        tensor *= ph\n",
    "\n",
    "        if rows < cols:\n",
    "            tensor = tensor.T\n",
    "        return tensor\n",
    "    \n",
    "    def get_weights(self):\n",
    "      \n",
    "        return deepcopy(self.weights)\n",
    "    \n",
    "    def set_weights(self, weights):\n",
    "\n",
    "        self.weights = deepcopy(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Adam Optimizer\n",
    "\n",
    " \n",
    "$$\\mathbf{m_t} = \\beta_m \\mathbf{m_{t-1}} + (1 - \\beta_m)g_t \\\\\n",
    "\\mathbf{v_t} = \\beta_v \\mathbf{v_{t-1}} + (1 - \\beta_v)g^2_t\n",
    "$$\n",
    "\n",
    "Here, $\\beta_m$ and $\\beta_v$ are fixed parameters controlling the linear combinations above and $g_t$ is the update at time $t$ (generally the gradients, but here the TD error times the gradients).\n",
    "\n",
    "Given that $\\mathbf{m}$ and $\\mathbf{v}$ are initialized to zero, they are biased toward zero. To get unbiased estimates of the mean and second moment, Adam defines $\\mathbf{\\hat{m}}$ and $\\mathbf{\\hat{v}}$ as:\n",
    "$$ \\mathbf{\\hat{m}_t} = \\frac{\\mathbf{m_t}}{1 - \\beta_m^t} \\\\\n",
    "\\mathbf{\\hat{v}_t} = \\frac{\\mathbf{v_t}}{1 - \\beta_v^t}\n",
    "$$\n",
    "\n",
    "The weights are then updated as follows:\n",
    "$$ \\mathbf{w_t} = \\mathbf{w_{t-1}} + \\frac{\\alpha}{\\sqrt{\\mathbf{\\hat{v}_t}}+\\epsilon} \\mathbf{\\hat{m}_t}\n",
    "$$\n",
    "\n",
    "Here, $\\alpha$ is the step size parameter and $\\epsilon$ is another small parameter to keep the denominator from being zero.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adam():\n",
    "    def __init__(self, layer_sizes, \n",
    "                 optimizer_info):\n",
    "        self.layer_sizes = layer_sizes\n",
    "\n",
    "        # Specify Adam algorithm's hyper parameters\n",
    "        self.step_size = optimizer_info.get(\"step_size\")\n",
    "        self.beta_m = optimizer_info.get(\"beta_m\")\n",
    "        self.beta_v = optimizer_info.get(\"beta_v\")\n",
    "        self.epsilon = optimizer_info.get(\"epsilon\")\n",
    "        \n",
    "        # Initialize Adam algorithm's m and v\n",
    "        self.m = [dict() for i in range(1, len(self.layer_sizes))]\n",
    "        self.v = [dict() for i in range(1, len(self.layer_sizes))]\n",
    "        \n",
    "        for i in range(0, len(self.layer_sizes) - 1):\n",
    "            self.m[i][\"W\"] = np.zeros((self.layer_sizes[i],self.layer_sizes[i+1]))\n",
    "            self.m[i][\"b\"] = np.zeros( (1,self.layer_sizes[i+1]) )\n",
    "            self.v[i][\"W\"] = np.zeros((self.layer_sizes[i],self.layer_sizes[i+1]))\n",
    "            self.v[i][\"b\"] = np.zeros( (1,self.layer_sizes[i+1]) )\n",
    "        self.beta_m_product = self.beta_m\n",
    "        self.beta_v_product = self.beta_v\n",
    "    \n",
    "    def update_weights(self, weights, td_errors_times_gradients):\n",
    "    \n",
    "        for i in range(len(weights)):\n",
    "            for param in weights[i].keys():\n",
    "                self.m[i][param] = (self.beta_m * self.m[i][param]) + (1-self.beta_m) * td_errors_times_gradients[i][param]\n",
    "                m_hat = self.m[i][param] / (1-self.beta_m_product)\n",
    "                self.v[i][param] = (self.beta_v * self.v[i][param]) + (1-self.beta_v)*(td_errors_times_gradients[i][param]**2)\n",
    "                v_hat = self.v[i][param] / (1-self.beta_v_product)\n",
    "                weight_update = (self.step_size * m_hat) / (v_hat**0.5 + self.epsilon )            \n",
    "                weights[i][param] = weights[i][param] + weight_update\n",
    "        self.beta_m_product *= self.beta_m\n",
    "        self.beta_v_product *= self.beta_v\n",
    "        \n",
    "        return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Experience Replay Buffers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    def __init__(self, size, minibatch_size, seed):\n",
    "\n",
    "        self.buffer = []\n",
    "        self.minibatch_size = minibatch_size\n",
    "        self.rand_generator = np.random.RandomState(seed)\n",
    "        self.max_size = size\n",
    "\n",
    "    def append(self, state, action, reward, terminal, next_state):\n",
    "  \n",
    "        if len(self.buffer) == self.max_size:\n",
    "            del self.buffer[0]\n",
    "        self.buffer.append([state, action, reward, terminal, next_state])\n",
    "\n",
    "    def sample(self):\n",
    "#Returns: A list of transition tuples including state, action, reward, terinal, and next_state\n",
    "         \n",
    "        idxs = self.rand_generator.choice(np.arange(len(self.buffer)), size=self.minibatch_size)\n",
    "        return [self.buffer[idx] for idx in idxs]\n",
    "\n",
    "    def size(self):\n",
    "        return len(self.buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Softmax Policy\n",
    "\n",
    "\n",
    "The probability of selecting each action according to the softmax policy is shown below:\n",
    "$$Pr{(A_t=a | S_t=s)} \\hspace{0.1cm} \\dot{=} \\hspace{0.1cm} \\frac{e^{Q(s, a)/\\tau}}{\\sum_{b \\in A}e^{Q(s, b)/\\tau}}$$\n",
    "where $\\tau$ is the temperature parameter which controls how much the agent focuses on the highest valued actions.  \n",
    " \n",
    " In a numerically stable (softmax policy) , using  maximum action-value from the action-values.The probability of selecting each action looks as follows:\n",
    "\n",
    "$$Pr{(A_t=a | S_t=s)} \\hspace{0.1cm} \\dot{=} \\hspace{0.1cm} \\frac{e^{Q(s, a)/\\tau - max_{c}Q(s, c)/\\tau}}{\\sum_{b \\in A}e^{Q(s, b)/\\tau - max_{c}Q(s, c)/\\tau}}$$\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(action_values, tau=1.0):\n",
    "    preferences = action_values / tau\n",
    "    max_preference = np.max(preferences,axis=1)\n",
    "    reshaped_max_preference = max_preference.reshape((-1, 1))\n",
    "    exp_preferences = np.exp(preferences - reshaped_max_preference)\n",
    "    sum_of_exp_preferences = np.sum(exp_preferences,axis=1)\n",
    "    reshaped_sum_of_exp_preferences = sum_of_exp_preferences.reshape((-1, 1))\n",
    "    action_probs = exp_preferences / reshaped_sum_of_exp_preferences\n",
    "    action_probs = action_probs.squeeze()\n",
    "    return action_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "& Q_t \\leftarrow \\text{action-value network at timestep t (current action-value network)}\\\\\n",
    "& \\text{Initialize } Q_{t+1}^1 \\leftarrow Q_t\\\\\n",
    "& \\text{For } i \\text{ in } [1, ..., N] \\text{ (i.e. N} \\text{  replay steps)}:\\\\\n",
    "& \\hspace{1cm} s, a, r, t, s'\n",
    "\\leftarrow \\text{Sample batch of experiences from experience replay buffer} \\\\\n",
    "& \\hspace{1cm} \\text{Do Expected Sarsa update with } Q_t: Q_{t+1}^{i+1}(s, a) \\leftarrow Q_{t+1}^{i}(s, a) + \\alpha \\cdot \\left[r + \\gamma \\left(\\sum_{b} \\pi(b | s') Q_t(s', b)\\right) - Q_{t+1}^{i}(s, a)\\right]\\\\\n",
    "& \\hspace{1.5cm} \\text{ making sure to add the } \\gamma \\left(\\sum_{b} \\pi(b | s') Q_t(s', b)\\right) \\text{ for non-terminal transitions only.} \\\\\n",
    "& \\text{After N replay steps,   set } Q_{t+1}^{N} \\text{ as } Q_{t+1} \\text{ and have a new } Q_{t+1} \\text{for time step } t + 1 \\text{ that   will fix in the next set of updates. }\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_td_error(states, next_states, actions, rewards, discount, terminals, network, current_q, tau):\n",
    "    q_next_mat = current_q.get_action_values(next_states)\n",
    "    probs_mat = softmax(q_next_mat,tau)\n",
    "    v_next_vec = np.sum(q_next_mat * probs_mat,axis=1)*(1-terminals)\n",
    "    target_vec = rewards + discount*v_next_vec\n",
    "    q_mat = network.get_action_values(states)\n",
    "    batch_indices = np.arange(q_mat.shape[0])\n",
    "    q_vec = q_mat[batch_indices,actions]\n",
    "    delta_vec = target_vec - q_vec\n",
    "    \n",
    "    return delta_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    " def optimize_network(experiences, discount, optimizer, network, current_q, tau):\n",
    " \n",
    "    states, actions, rewards, terminals, next_states = map(list, zip(*experiences))\n",
    "    states = np.concatenate(states)\n",
    "    next_states = np.concatenate(next_states)\n",
    "    rewards = np.array(rewards)\n",
    "    terminals = np.array(terminals)\n",
    "    batch_size = states.shape[0]\n",
    "    delta_vec = get_td_error(states, next_states, actions, rewards, discount, terminals, network, current_q, tau)\n",
    "    batch_indices = np.arange(batch_size)\n",
    "    delta_mat = np.zeros((batch_size, network.num_actions))\n",
    "    delta_mat[batch_indices, actions] = delta_vec\n",
    "    td_update = network.get_TD_update(states,delta_mat)\n",
    "    weights = optimizer.update_weights(network.get_weights(), td_update)\n",
    "\n",
    "    network.set_weights(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent(BaseAgent):\n",
    "    def __init__(self):\n",
    "        self.name = \"expected_sarsa_agent\"\n",
    "        \n",
    "    def agent_init(self, agent_config):\n",
    "    \n",
    "        self.replay_buffer = ReplayBuffer(agent_config['replay_buffer_size'], \n",
    "                                          agent_config['minibatch_sz'], agent_config.get(\"seed\"))\n",
    "        self.network = ActionValueNetwork(agent_config['network_config'])\n",
    "        self.optimizer = Adam(self.network.layer_sizes, agent_config[\"optimizer_config\"])\n",
    "        self.num_actions = agent_config['network_config']['num_actions']\n",
    "        self.num_replay = agent_config['num_replay_updates_per_step']\n",
    "        self.discount = agent_config['gamma']\n",
    "        self.tau = agent_config['tau']\n",
    "        \n",
    "        self.rand_generator = np.random.RandomState(agent_config.get(\"seed\"))\n",
    "        \n",
    "        self.last_state = None\n",
    "        self.last_action = None\n",
    "        \n",
    "        self.sum_rewards = 0\n",
    "        self.episode_steps = 0\n",
    "\n",
    "    def policy(self, state):\n",
    " \n",
    "        action_values = self.network.get_action_values(state)\n",
    "        probs_batch = softmax(action_values, self.tau)\n",
    "        action = self.rand_generator.choice(self.num_actions, p=probs_batch.squeeze())\n",
    "        return action\n",
    "    \n",
    "    def agent_start(self, state):\n",
    "\n",
    "        self.sum_rewards = 0\n",
    "        self.episode_steps = 0\n",
    "        self.last_state = np.array([state])\n",
    "        self.last_action = self.policy(self.last_state)\n",
    "        return self.last_action\n",
    "\n",
    "\n",
    "    def agent_step(self, reward, state):\n",
    "     \n",
    "        self.sum_rewards += reward\n",
    "        self.episode_steps += 1\n",
    "\n",
    "    \n",
    "        state = np.array([state])\n",
    "\n",
    " \n",
    "        action = self.policy(state)\n",
    "\n",
    "        self.replay_buffer.append(self.last_state, self.last_action, reward, 0, state)\n",
    "    \n",
    "        if self.replay_buffer.size() > self.replay_buffer.minibatch_size:\n",
    "            current_q = deepcopy(self.network)\n",
    "            for _ in range(self.num_replay):\n",
    "                experiences = self.replay_buffer.sample()\n",
    "                optimize_network(experiences,self.discount,self.optimizer,self.network,current_q,self.tau)\n",
    "        self.last_state = state\n",
    "        self.last_action = action\n",
    "        \n",
    "        return action\n",
    "\n",
    "    def agent_end(self, reward):\n",
    "\n",
    "        self.sum_rewards += reward\n",
    "        self.episode_steps += 1\n",
    "        state = np.zeros_like(self.last_state)\n",
    "        self.replay_buffer.append(self.last_state,self.last_action,reward,1,state)\n",
    "        if self.replay_buffer.size() > self.replay_buffer.minibatch_size:\n",
    "            current_q = deepcopy(self.network)\n",
    "            for _ in range(self.num_replay):\n",
    "                experiences = self.replay_buffer.sample()\n",
    "                optimize_network(experiences,self.discount,self.optimizer,self.network,current_q,self.tau)\n",
    "                \n",
    "        \n",
    "    def agent_message(self, message):\n",
    "        if message == \"get_sum_reward\":\n",
    "            return self.sum_rewards\n",
    "        else:\n",
    "            raise Exception(\"Unrecognized Message!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/300 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 1/300 [00:00<00:58,  5.09it/s]\u001b[A\n",
      "  1%|          | 2/300 [00:00<00:55,  5.37it/s]\u001b[A\n",
      "  1%|          | 3/300 [00:01<01:54,  2.61it/s]\u001b[A\n",
      "  1%|▏         | 4/300 [00:01<02:03,  2.40it/s]\u001b[A\n",
      "  2%|▏         | 5/300 [00:02<01:54,  2.59it/s]\u001b[A\n",
      "  2%|▏         | 6/300 [00:02<02:02,  2.40it/s]\u001b[A\n",
      "  2%|▏         | 7/300 [00:02<01:56,  2.52it/s]\u001b[A\n",
      "  3%|▎         | 8/300 [00:03<02:12,  2.20it/s]\u001b[A\n",
      "  3%|▎         | 9/300 [00:04<02:43,  1.78it/s]\u001b[A\n",
      "  3%|▎         | 10/300 [00:04<02:57,  1.64it/s]\u001b[A\n",
      "  4%|▎         | 11/300 [00:05<02:30,  1.92it/s]\u001b[A\n",
      "  4%|▍         | 12/300 [00:05<02:02,  2.36it/s]\u001b[A\n",
      "  4%|▍         | 13/300 [00:06<02:26,  1.95it/s]\u001b[A\n",
      "  5%|▍         | 14/300 [00:06<02:44,  1.74it/s]\u001b[A\n",
      "  5%|▌         | 15/300 [00:07<02:22,  2.00it/s]\u001b[A\n",
      "  5%|▌         | 16/300 [00:07<02:38,  1.79it/s]\u001b[A\n",
      "  6%|▌         | 17/300 [00:08<02:35,  1.82it/s]\u001b[A\n",
      "  6%|▌         | 18/300 [00:09<02:55,  1.61it/s]\u001b[A\n",
      "  6%|▋         | 19/300 [00:12<06:33,  1.40s/it]\u001b[A\n",
      "  7%|▋         | 20/300 [00:13<05:36,  1.20s/it]\u001b[A\n",
      "  7%|▋         | 21/300 [00:14<05:15,  1.13s/it]\u001b[A\n",
      "  7%|▋         | 22/300 [00:14<04:42,  1.02s/it]\u001b[A\n",
      "  8%|▊         | 23/300 [00:15<04:15,  1.09it/s]\u001b[A\n",
      "  8%|▊         | 24/300 [00:16<03:43,  1.24it/s]\u001b[A\n",
      "  8%|▊         | 25/300 [00:17<03:44,  1.23it/s]\u001b[A\n",
      "  9%|▊         | 26/300 [00:17<03:26,  1.33it/s]\u001b[A\n",
      "  9%|▉         | 27/300 [00:19<04:21,  1.04it/s]\u001b[A\n",
      "  9%|▉         | 28/300 [00:20<04:30,  1.01it/s]\u001b[A\n",
      " 10%|▉         | 29/300 [00:23<08:16,  1.83s/it]\u001b[A\n",
      " 10%|█         | 30/300 [00:26<09:04,  2.02s/it]\u001b[A\n",
      " 10%|█         | 31/300 [00:27<07:29,  1.67s/it]\u001b[A\n",
      " 11%|█         | 32/300 [00:28<06:19,  1.42s/it]\u001b[A\n",
      " 11%|█         | 33/300 [00:31<08:56,  2.01s/it]\u001b[A\n",
      " 11%|█▏        | 34/300 [00:32<07:01,  1.59s/it]\u001b[A\n",
      " 12%|█▏        | 35/300 [00:32<05:54,  1.34s/it]\u001b[A\n",
      " 12%|█▏        | 36/300 [00:35<08:17,  1.88s/it]\u001b[A\n",
      " 12%|█▏        | 37/300 [00:39<10:06,  2.31s/it]\u001b[A\n",
      " 13%|█▎        | 38/300 [00:40<08:13,  1.88s/it]\u001b[A\n",
      " 13%|█▎        | 39/300 [00:44<10:52,  2.50s/it]\u001b[A\n",
      " 13%|█▎        | 40/300 [00:47<12:04,  2.79s/it]\u001b[A\n",
      " 14%|█▎        | 41/300 [00:48<09:10,  2.13s/it]\u001b[A\n",
      " 14%|█▍        | 42/300 [00:51<10:21,  2.41s/it]\u001b[A\n",
      " 14%|█▍        | 43/300 [00:55<12:12,  2.85s/it]\u001b[A\n",
      " 15%|█▍        | 44/300 [00:59<13:44,  3.22s/it]\u001b[A\n",
      " 15%|█▌        | 45/300 [01:02<14:03,  3.31s/it]\u001b[A\n",
      " 15%|█▌        | 46/300 [01:06<14:23,  3.40s/it]\u001b[A\n",
      " 16%|█▌        | 47/300 [01:10<14:53,  3.53s/it]\u001b[A\n",
      " 16%|█▌        | 48/300 [01:13<14:49,  3.53s/it]\u001b[A\n",
      " 16%|█▋        | 49/300 [01:17<14:40,  3.51s/it]\u001b[A\n",
      " 17%|█▋        | 50/300 [01:21<15:31,  3.73s/it]\u001b[A\n",
      " 17%|█▋        | 51/300 [01:24<15:18,  3.69s/it]\u001b[A\n",
      " 17%|█▋        | 52/300 [01:28<14:55,  3.61s/it]\u001b[A\n",
      " 18%|█▊        | 53/300 [01:29<11:18,  2.75s/it]\u001b[A\n",
      " 18%|█▊        | 54/300 [01:29<08:26,  2.06s/it]\u001b[A\n",
      " 18%|█▊        | 55/300 [01:32<09:30,  2.33s/it]\u001b[A\n",
      " 19%|█▊        | 56/300 [01:34<08:40,  2.13s/it]\u001b[A\n",
      " 19%|█▉        | 57/300 [01:35<07:26,  1.84s/it]\u001b[A\n",
      " 19%|█▉        | 58/300 [01:39<10:14,  2.54s/it]\u001b[A\n",
      " 20%|█▉        | 59/300 [01:42<10:35,  2.64s/it]\u001b[A\n",
      " 20%|██        | 60/300 [01:46<11:56,  2.98s/it]\u001b[A\n",
      " 20%|██        | 61/300 [01:49<12:41,  3.18s/it]\u001b[A\n",
      " 21%|██        | 62/300 [01:50<09:34,  2.41s/it]\u001b[A\n",
      " 21%|██        | 63/300 [01:53<10:34,  2.68s/it]\u001b[A\n",
      " 21%|██▏       | 64/300 [01:57<12:04,  3.07s/it]\u001b[A\n",
      " 22%|██▏       | 65/300 [02:02<13:30,  3.45s/it]\u001b[A\n",
      " 22%|██▏       | 66/300 [02:06<14:11,  3.64s/it]\u001b[A\n",
      " 22%|██▏       | 67/300 [02:09<14:03,  3.62s/it]\u001b[A\n",
      " 23%|██▎       | 68/300 [02:12<13:00,  3.37s/it]\u001b[A\n",
      " 23%|██▎       | 69/300 [02:15<13:03,  3.39s/it]\u001b[A\n",
      " 23%|██▎       | 70/300 [02:19<13:07,  3.43s/it]\u001b[A\n",
      " 24%|██▎       | 71/300 [02:23<14:07,  3.70s/it]\u001b[A\n",
      " 24%|██▍       | 72/300 [02:24<10:15,  2.70s/it]\u001b[A\n",
      " 24%|██▍       | 73/300 [02:28<11:48,  3.12s/it]\u001b[A\n",
      " 25%|██▍       | 74/300 [02:31<12:10,  3.23s/it]\u001b[A\n",
      " 25%|██▌       | 75/300 [02:36<13:23,  3.57s/it]\u001b[A\n",
      " 25%|██▌       | 76/300 [02:39<12:47,  3.43s/it]\u001b[A\n",
      " 26%|██▌       | 77/300 [02:42<12:50,  3.45s/it]\u001b[A\n",
      " 26%|██▌       | 78/300 [02:46<12:47,  3.46s/it]\u001b[A\n",
      " 26%|██▋       | 79/300 [02:49<12:29,  3.39s/it]\u001b[A\n",
      " 27%|██▋       | 80/300 [02:53<12:44,  3.48s/it]\u001b[A\n",
      " 27%|██▋       | 81/300 [02:55<11:45,  3.22s/it]\u001b[A\n",
      " 27%|██▋       | 82/300 [02:58<11:36,  3.20s/it]\u001b[A\n",
      " 28%|██▊       | 83/300 [03:02<12:04,  3.34s/it]\u001b[A\n",
      " 28%|██▊       | 84/300 [03:06<12:12,  3.39s/it]\u001b[A\n",
      " 28%|██▊       | 85/300 [03:09<12:30,  3.49s/it]\u001b[A\n",
      " 29%|██▊       | 86/300 [03:12<12:06,  3.40s/it]\u001b[A\n",
      " 29%|██▉       | 87/300 [03:16<12:41,  3.58s/it]\u001b[A\n",
      " 29%|██▉       | 88/300 [03:21<13:09,  3.73s/it]\u001b[A\n",
      " 30%|██▉       | 89/300 [03:24<12:46,  3.63s/it]\u001b[A\n",
      " 30%|███       | 90/300 [03:27<12:23,  3.54s/it]\u001b[A\n",
      " 30%|███       | 91/300 [03:28<08:56,  2.57s/it]\u001b[A\n",
      " 31%|███       | 92/300 [03:32<10:22,  2.99s/it]\u001b[A\n",
      " 31%|███       | 93/300 [03:35<11:17,  3.27s/it]\u001b[A\n",
      " 31%|███▏      | 94/300 [03:40<12:10,  3.54s/it]\u001b[A\n",
      " 32%|███▏      | 95/300 [03:44<12:34,  3.68s/it]\u001b[A\n",
      " 32%|███▏      | 96/300 [03:47<12:31,  3.68s/it]\u001b[A\n",
      " 32%|███▏      | 97/300 [03:51<12:46,  3.78s/it]\u001b[A\n",
      " 33%|███▎      | 98/300 [03:54<12:04,  3.59s/it]\u001b[A\n",
      " 33%|███▎      | 99/300 [03:59<12:45,  3.81s/it]\u001b[A\n",
      " 33%|███▎      | 100/300 [04:03<12:41,  3.81s/it]\u001b[A\n",
      " 34%|███▎      | 101/300 [04:06<12:20,  3.72s/it]\u001b[A\n",
      " 34%|███▍      | 102/300 [04:10<11:58,  3.63s/it]\u001b[A\n",
      " 34%|███▍      | 103/300 [04:14<12:29,  3.81s/it]\u001b[A\n",
      " 35%|███▍      | 104/300 [04:17<12:06,  3.71s/it]\u001b[A\n",
      " 35%|███▌      | 105/300 [04:22<12:45,  3.93s/it]\u001b[A\n",
      " 35%|███▌      | 106/300 [04:25<12:16,  3.80s/it]\u001b[A\n",
      " 36%|███▌      | 107/300 [04:29<12:16,  3.82s/it]\u001b[A\n",
      " 36%|███▌      | 108/300 [04:32<11:45,  3.67s/it]\u001b[A\n",
      " 36%|███▋      | 109/300 [04:36<11:21,  3.57s/it]\u001b[A\n",
      " 37%|███▋      | 110/300 [04:39<10:52,  3.43s/it]\u001b[A\n",
      " 37%|███▋      | 111/300 [04:43<11:49,  3.75s/it]\u001b[A\n",
      " 37%|███▋      | 112/300 [04:47<12:07,  3.87s/it]\u001b[A\n",
      " 38%|███▊      | 113/300 [04:51<11:27,  3.67s/it]\u001b[A\n",
      " 38%|███▊      | 114/300 [04:54<11:26,  3.69s/it]\u001b[A\n",
      " 38%|███▊      | 115/300 [04:58<11:12,  3.64s/it]\u001b[A\n",
      " 39%|███▊      | 116/300 [05:02<11:11,  3.65s/it]\u001b[A\n",
      " 39%|███▉      | 117/300 [05:02<08:19,  2.73s/it]\u001b[A\n",
      " 39%|███▉      | 118/300 [05:03<06:13,  2.05s/it]\u001b[A\n",
      " 40%|███▉      | 119/300 [05:07<08:19,  2.76s/it]\u001b[A\n",
      " 40%|████      | 120/300 [05:11<09:11,  3.06s/it]\u001b[A\n",
      " 40%|████      | 121/300 [05:15<09:43,  3.26s/it]\u001b[A\n",
      " 41%|████      | 122/300 [05:19<10:39,  3.59s/it]\u001b[A\n",
      " 41%|████      | 123/300 [05:23<11:00,  3.73s/it]\u001b[A\n",
      " 41%|████▏     | 124/300 [05:26<10:35,  3.61s/it]\u001b[A\n",
      " 42%|████▏     | 125/300 [05:30<10:25,  3.57s/it]\u001b[A\n",
      " 42%|████▏     | 126/300 [05:33<10:19,  3.56s/it]\u001b[A\n",
      " 42%|████▏     | 127/300 [05:34<07:23,  2.56s/it]\u001b[A\n",
      " 43%|████▎     | 128/300 [05:37<08:29,  2.96s/it]\u001b[A\n",
      " 43%|████▎     | 129/300 [05:41<09:04,  3.18s/it]\u001b[A\n",
      " 43%|████▎     | 130/300 [05:45<09:42,  3.43s/it]\u001b[A\n",
      " 44%|████▎     | 131/300 [05:50<10:47,  3.83s/it]\u001b[A\n",
      " 44%|████▍     | 132/300 [05:53<10:16,  3.67s/it]\u001b[A\n",
      " 44%|████▍     | 133/300 [05:57<10:25,  3.75s/it]\u001b[A\n",
      " 45%|████▍     | 134/300 [06:01<10:04,  3.64s/it]\u001b[A\n",
      " 45%|████▌     | 135/300 [06:04<10:17,  3.74s/it]\u001b[A\n",
      " 45%|████▌     | 136/300 [06:05<07:48,  2.86s/it]\u001b[A\n",
      " 46%|████▌     | 137/300 [06:10<09:11,  3.38s/it]\u001b[A\n",
      " 46%|████▌     | 138/300 [06:13<09:18,  3.45s/it]\u001b[A\n",
      " 46%|████▋     | 139/300 [06:17<09:10,  3.42s/it]\u001b[A\n",
      " 47%|████▋     | 140/300 [06:20<08:58,  3.37s/it]\u001b[A\n",
      " 47%|████▋     | 141/300 [06:23<08:46,  3.31s/it]\u001b[A\n",
      " 47%|████▋     | 142/300 [06:25<07:47,  2.96s/it]\u001b[A\n",
      " 48%|████▊     | 143/300 [06:27<06:56,  2.65s/it]\u001b[A\n",
      " 48%|████▊     | 144/300 [06:31<07:26,  2.86s/it]\u001b[A\n",
      " 48%|████▊     | 145/300 [06:35<08:20,  3.23s/it]\u001b[A\n",
      " 49%|████▊     | 146/300 [06:38<08:24,  3.28s/it]\u001b[A\n",
      " 49%|████▉     | 147/300 [06:40<07:26,  2.92s/it]\u001b[A\n",
      " 49%|████▉     | 148/300 [06:44<07:47,  3.07s/it]\u001b[A\n",
      " 50%|████▉     | 149/300 [06:47<07:51,  3.13s/it]\u001b[A\n",
      " 50%|█████     | 150/300 [06:51<08:43,  3.49s/it]\u001b[A\n",
      " 50%|█████     | 151/300 [06:55<08:44,  3.52s/it]\u001b[A\n",
      " 51%|█████     | 152/300 [06:59<09:08,  3.71s/it]\u001b[A\n",
      " 51%|█████     | 153/300 [07:01<07:53,  3.22s/it]\u001b[A\n",
      " 51%|█████▏    | 154/300 [07:05<08:29,  3.49s/it]\u001b[A\n",
      " 52%|█████▏    | 155/300 [07:09<08:25,  3.48s/it]\u001b[A\n",
      " 52%|█████▏    | 156/300 [07:13<08:43,  3.64s/it]\u001b[A\n",
      " 52%|█████▏    | 157/300 [07:16<08:42,  3.65s/it]\u001b[A\n",
      " 53%|█████▎    | 158/300 [07:20<08:52,  3.75s/it]\u001b[A\n",
      " 53%|█████▎    | 159/300 [07:22<07:03,  3.00s/it]\u001b[A\n",
      " 53%|█████▎    | 160/300 [07:26<07:38,  3.28s/it]\u001b[A\n",
      " 54%|█████▎    | 161/300 [07:29<07:54,  3.41s/it]\u001b[A\n",
      " 54%|█████▍    | 162/300 [07:33<08:09,  3.54s/it]\u001b[A\n",
      " 54%|█████▍    | 163/300 [07:37<08:13,  3.60s/it]\u001b[A\n",
      " 55%|█████▍    | 164/300 [07:38<06:41,  2.95s/it]\u001b[A\n",
      " 55%|█████▌    | 165/300 [07:42<07:26,  3.30s/it]\u001b[A\n",
      " 55%|█████▌    | 166/300 [07:46<07:34,  3.39s/it]\u001b[A\n",
      " 56%|█████▌    | 167/300 [07:46<05:35,  2.53s/it]\u001b[A\n",
      " 56%|█████▌    | 168/300 [07:51<06:46,  3.08s/it]\u001b[A\n",
      " 56%|█████▋    | 169/300 [07:54<06:58,  3.19s/it]\u001b[A\n",
      " 57%|█████▋    | 170/300 [07:57<06:25,  2.97s/it]\u001b[A\n",
      " 57%|█████▋    | 171/300 [07:58<05:24,  2.52s/it]\u001b[A\n",
      " 57%|█████▋    | 172/300 [08:02<05:57,  2.79s/it]\u001b[A\n",
      " 58%|█████▊    | 173/300 [08:03<04:52,  2.31s/it]\u001b[A\n",
      " 58%|█████▊    | 174/300 [08:07<05:48,  2.76s/it]\u001b[A\n",
      " 58%|█████▊    | 175/300 [08:10<06:24,  3.08s/it]\u001b[A\n",
      " 59%|█████▊    | 176/300 [08:14<06:28,  3.13s/it]\u001b[A\n",
      " 59%|█████▉    | 177/300 [08:15<04:58,  2.42s/it]\u001b[A\n",
      " 59%|█████▉    | 178/300 [08:16<04:19,  2.12s/it]\u001b[A\n",
      " 60%|█████▉    | 179/300 [08:19<04:39,  2.31s/it]\u001b[A\n",
      " 60%|██████    | 180/300 [08:19<03:37,  1.81s/it]\u001b[A\n",
      " 60%|██████    | 181/300 [08:20<02:56,  1.49s/it]\u001b[A\n",
      " 61%|██████    | 182/300 [08:21<02:41,  1.37s/it]\u001b[A\n",
      " 61%|██████    | 183/300 [08:22<02:22,  1.22s/it]\u001b[A\n",
      " 61%|██████▏   | 184/300 [08:24<02:53,  1.50s/it]\u001b[A\n",
      " 62%|██████▏   | 185/300 [08:28<03:59,  2.08s/it]\u001b[A\n",
      " 62%|██████▏   | 186/300 [08:30<03:56,  2.08s/it]\u001b[A\n",
      " 62%|██████▏   | 187/300 [08:32<04:12,  2.23s/it]\u001b[A\n",
      " 63%|██████▎   | 188/300 [08:34<03:48,  2.04s/it]\u001b[A\n",
      " 63%|██████▎   | 189/300 [08:37<04:15,  2.30s/it]\u001b[A\n",
      " 63%|██████▎   | 190/300 [08:39<04:06,  2.24s/it]\u001b[A\n",
      " 64%|██████▎   | 191/300 [08:40<03:38,  2.01s/it]\u001b[A\n",
      " 64%|██████▍   | 192/300 [08:42<03:11,  1.77s/it]\u001b[A\n",
      " 64%|██████▍   | 193/300 [08:45<04:00,  2.25s/it]\u001b[A\n",
      " 65%|██████▍   | 194/300 [08:46<03:37,  2.05s/it]\u001b[A\n",
      " 65%|██████▌   | 195/300 [08:50<04:15,  2.43s/it]\u001b[A\n",
      " 65%|██████▌   | 196/300 [08:51<03:35,  2.07s/it]\u001b[A\n",
      " 66%|██████▌   | 197/300 [08:53<03:36,  2.11s/it]\u001b[A\n",
      " 66%|██████▌   | 198/300 [08:56<03:46,  2.22s/it]\u001b[A\n",
      " 66%|██████▋   | 199/300 [08:57<03:12,  1.90s/it]\u001b[A\n",
      " 67%|██████▋   | 200/300 [08:58<02:50,  1.70s/it]\u001b[A\n",
      " 67%|██████▋   | 201/300 [09:00<02:57,  1.80s/it]\u001b[A\n",
      " 67%|██████▋   | 202/300 [09:01<02:42,  1.65s/it]\u001b[A\n",
      " 68%|██████▊   | 203/300 [09:03<02:24,  1.49s/it]\u001b[A\n",
      " 68%|██████▊   | 204/300 [09:04<02:16,  1.42s/it]\u001b[A\n",
      " 68%|██████▊   | 205/300 [09:06<02:44,  1.73s/it]\u001b[A\n",
      " 69%|██████▊   | 206/300 [09:07<02:14,  1.43s/it]\u001b[A\n",
      " 69%|██████▉   | 207/300 [09:08<02:02,  1.32s/it]\u001b[A\n",
      " 69%|██████▉   | 208/300 [09:09<02:03,  1.34s/it]\u001b[A\n",
      " 70%|██████▉   | 209/300 [09:11<01:58,  1.31s/it]\u001b[A\n",
      " 70%|███████   | 210/300 [09:11<01:43,  1.15s/it]\u001b[A\n",
      " 70%|███████   | 211/300 [09:13<01:51,  1.26s/it]\u001b[A\n",
      " 71%|███████   | 212/300 [09:14<01:43,  1.17s/it]\u001b[A\n",
      " 71%|███████   | 213/300 [09:15<01:29,  1.03s/it]\u001b[A\n",
      " 71%|███████▏  | 214/300 [09:15<01:23,  1.03it/s]\u001b[A\n",
      " 72%|███████▏  | 215/300 [09:16<01:20,  1.06it/s]\u001b[A\n",
      " 72%|███████▏  | 216/300 [09:17<01:21,  1.03it/s]\u001b[A\n",
      " 72%|███████▏  | 217/300 [09:18<01:02,  1.32it/s]\u001b[A\n",
      " 73%|███████▎  | 218/300 [09:18<01:01,  1.32it/s]\u001b[A\n",
      " 73%|███████▎  | 219/300 [09:20<01:11,  1.14it/s]\u001b[A\n",
      " 73%|███████▎  | 220/300 [09:20<00:55,  1.43it/s]\u001b[A\n",
      " 74%|███████▎  | 221/300 [09:20<00:43,  1.83it/s]\u001b[A\n",
      " 74%|███████▍  | 222/300 [09:22<01:06,  1.18it/s]\u001b[A\n",
      " 74%|███████▍  | 223/300 [09:23<01:24,  1.10s/it]\u001b[A\n",
      " 75%|███████▍  | 224/300 [09:25<01:44,  1.37s/it]\u001b[A\n",
      " 75%|███████▌  | 225/300 [09:28<02:09,  1.72s/it]\u001b[A\n",
      " 75%|███████▌  | 226/300 [09:30<02:17,  1.86s/it]\u001b[A\n",
      " 76%|███████▌  | 227/300 [09:31<01:56,  1.59s/it]\u001b[A\n",
      " 76%|███████▌  | 228/300 [09:33<01:59,  1.66s/it]\u001b[A\n",
      " 76%|███████▋  | 229/300 [09:34<01:43,  1.46s/it]\u001b[A\n",
      " 77%|███████▋  | 230/300 [09:35<01:32,  1.32s/it]\u001b[A\n",
      " 77%|███████▋  | 231/300 [09:35<01:18,  1.14s/it]\u001b[A\n",
      " 77%|███████▋  | 232/300 [09:39<02:00,  1.77s/it]\u001b[A\n",
      " 78%|███████▊  | 233/300 [09:41<02:02,  1.82s/it]\u001b[A\n",
      " 78%|███████▊  | 234/300 [09:42<01:55,  1.76s/it]\u001b[A\n",
      " 78%|███████▊  | 235/300 [09:43<01:34,  1.46s/it]\u001b[A\n",
      " 79%|███████▊  | 236/300 [09:45<01:50,  1.73s/it]\u001b[A\n",
      " 79%|███████▉  | 237/300 [09:48<02:13,  2.12s/it]\u001b[A\n",
      " 79%|███████▉  | 238/300 [09:49<01:45,  1.71s/it]\u001b[A\n",
      " 80%|███████▉  | 239/300 [09:50<01:27,  1.43s/it]\u001b[A\n",
      " 80%|████████  | 240/300 [09:54<02:05,  2.10s/it]\u001b[A\n",
      " 80%|████████  | 241/300 [09:56<02:15,  2.30s/it]\u001b[A\n",
      " 81%|████████  | 242/300 [09:58<01:59,  2.07s/it]\u001b[A\n",
      " 81%|████████  | 243/300 [09:59<01:41,  1.78s/it]\u001b[A\n",
      " 81%|████████▏ | 244/300 [10:00<01:24,  1.50s/it]\u001b[A\n",
      " 82%|████████▏ | 245/300 [10:02<01:28,  1.62s/it]\u001b[A\n",
      " 82%|████████▏ | 246/300 [10:03<01:24,  1.56s/it]\u001b[A\n",
      " 82%|████████▏ | 247/300 [10:04<01:13,  1.39s/it]\u001b[A\n",
      " 83%|████████▎ | 248/300 [10:05<01:04,  1.25s/it]\u001b[A\n",
      " 83%|████████▎ | 249/300 [10:06<01:02,  1.22s/it]\u001b[A\n",
      " 83%|████████▎ | 250/300 [10:08<01:09,  1.38s/it]\u001b[A\n",
      " 84%|████████▎ | 251/300 [10:10<01:17,  1.58s/it]\u001b[A\n",
      " 84%|████████▍ | 252/300 [10:11<01:12,  1.51s/it]\u001b[A\n",
      " 84%|████████▍ | 253/300 [10:13<01:10,  1.50s/it]\u001b[A\n",
      " 85%|████████▍ | 254/300 [10:15<01:11,  1.56s/it]\u001b[A\n",
      " 85%|████████▌ | 255/300 [10:18<01:37,  2.16s/it]\u001b[A\n",
      " 85%|████████▌ | 256/300 [10:20<01:26,  1.96s/it]\u001b[A\n",
      " 86%|████████▌ | 257/300 [10:21<01:11,  1.66s/it]\u001b[A\n",
      " 86%|████████▌ | 258/300 [10:21<00:56,  1.34s/it]\u001b[A\n",
      " 86%|████████▋ | 259/300 [10:21<00:41,  1.01s/it]\u001b[A\n",
      " 87%|████████▋ | 260/300 [10:23<00:44,  1.11s/it]\u001b[A\n",
      " 87%|████████▋ | 261/300 [10:25<00:51,  1.32s/it]\u001b[A\n",
      " 87%|████████▋ | 262/300 [10:26<00:46,  1.23s/it]\u001b[A\n",
      " 88%|████████▊ | 263/300 [10:26<00:41,  1.13s/it]\u001b[A\n",
      " 88%|████████▊ | 264/300 [10:28<00:41,  1.14s/it]\u001b[A\n",
      " 88%|████████▊ | 265/300 [10:30<00:51,  1.48s/it]\u001b[A\n",
      " 89%|████████▊ | 266/300 [10:31<00:48,  1.43s/it]\u001b[A\n",
      " 89%|████████▉ | 267/300 [10:32<00:38,  1.16s/it]\u001b[A\n",
      " 89%|████████▉ | 268/300 [10:32<00:31,  1.00it/s]\u001b[A\n",
      " 90%|████████▉ | 269/300 [10:33<00:28,  1.07it/s]\u001b[A\n",
      " 90%|█████████ | 270/300 [10:34<00:25,  1.17it/s]\u001b[A\n",
      " 90%|█████████ | 271/300 [10:35<00:29,  1.03s/it]\u001b[A\n",
      " 91%|█████████ | 272/300 [10:36<00:27,  1.01it/s]\u001b[A\n",
      " 91%|█████████ | 273/300 [10:37<00:26,  1.03it/s]\u001b[A\n",
      " 91%|█████████▏| 274/300 [10:38<00:25,  1.04it/s]\u001b[A\n",
      " 92%|█████████▏| 275/300 [10:39<00:25,  1.04s/it]\u001b[A\n",
      " 92%|█████████▏| 276/300 [10:40<00:25,  1.06s/it]\u001b[A\n",
      " 92%|█████████▏| 277/300 [10:42<00:25,  1.11s/it]\u001b[A\n",
      " 93%|█████████▎| 278/300 [10:43<00:25,  1.16s/it]\u001b[A\n",
      " 93%|█████████▎| 279/300 [10:44<00:26,  1.28s/it]\u001b[A\n",
      " 93%|█████████▎| 280/300 [10:46<00:29,  1.50s/it]\u001b[A\n",
      " 94%|█████████▎| 281/300 [10:48<00:26,  1.39s/it]\u001b[A\n",
      " 94%|█████████▍| 282/300 [10:49<00:22,  1.25s/it]\u001b[A\n",
      " 94%|█████████▍| 283/300 [10:50<00:20,  1.23s/it]\u001b[A\n",
      " 95%|█████████▍| 284/300 [10:51<00:20,  1.27s/it]\u001b[A\n",
      " 95%|█████████▌| 285/300 [10:52<00:18,  1.25s/it]\u001b[A\n",
      " 95%|█████████▌| 286/300 [10:54<00:17,  1.27s/it]\u001b[A\n",
      " 96%|█████████▌| 287/300 [10:54<00:13,  1.06s/it]\u001b[A\n",
      " 96%|█████████▌| 288/300 [10:55<00:12,  1.07s/it]\u001b[A\n",
      " 96%|█████████▋| 289/300 [10:56<00:10,  1.04it/s]\u001b[A\n",
      " 97%|█████████▋| 290/300 [10:57<00:10,  1.07s/it]\u001b[A\n",
      " 97%|█████████▋| 291/300 [10:59<00:10,  1.19s/it]\u001b[A\n",
      " 97%|█████████▋| 292/300 [11:00<00:09,  1.19s/it]\u001b[A\n",
      " 98%|█████████▊| 293/300 [11:01<00:08,  1.21s/it]\u001b[A\n",
      " 98%|█████████▊| 294/300 [11:03<00:07,  1.24s/it]\u001b[A\n",
      " 98%|█████████▊| 295/300 [11:03<00:05,  1.07s/it]\u001b[A\n",
      " 99%|█████████▊| 296/300 [11:04<00:03,  1.15it/s]\u001b[A\n",
      " 99%|█████████▉| 297/300 [11:04<00:02,  1.27it/s]\u001b[A\n",
      " 99%|█████████▉| 298/300 [11:05<00:01,  1.15it/s]\u001b[A\n",
      "100%|█████████▉| 299/300 [11:07<00:01,  1.08s/it]\u001b[A\n",
      "100%|██████████| 300/300 [11:07<00:00,  2.23s/it]\u001b[A\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def run_experiment(environment, agent, environment_parameters, agent_parameters, experiment_parameters):\n",
    "    \n",
    "    rl_glue = RLGlue(environment, agent)\n",
    "        \n",
    "    # save sum of reward at the end of each episode\n",
    "    agent_sum_reward = np.zeros((experiment_parameters[\"num_runs\"], \n",
    "                                 experiment_parameters[\"num_episodes\"]))\n",
    "\n",
    "    env_info = {}\n",
    "\n",
    "    agent_info = agent_parameters\n",
    "\n",
    "    # one agent setting\n",
    "    for run in range(1, experiment_parameters[\"num_runs\"]+1):\n",
    "        agent_info[\"seed\"] = run\n",
    "        agent_info[\"network_config\"][\"seed\"] = run\n",
    "        env_info[\"seed\"] = run\n",
    "\n",
    "        rl_glue.rl_init(agent_info, env_info)\n",
    "        \n",
    "        for episode in tqdm(range(1, experiment_parameters[\"num_episodes\"]+1)):\n",
    "            # run episode\n",
    "            rl_glue.rl_episode(experiment_parameters[\"timeout\"])\n",
    "            \n",
    "            episode_reward = rl_glue.rl_agent_message(\"get_sum_reward\")\n",
    "            agent_sum_reward[run - 1, episode - 1] = episode_reward\n",
    "    save_name = \"{}\".format(rl_glue.agent.name)\n",
    "    if not os.path.exists('results'):\n",
    "        os.makedirs('results')\n",
    "    np.save(\"results/sum_reward_{}\".format(save_name), agent_sum_reward)\n",
    "    shutil.make_archive('results', 'zip', 'results')\n",
    "\n",
    "# Run Experiment\n",
    "\n",
    "# Experiment parameters\n",
    "experiment_parameters = {\n",
    "    \"num_runs\" : 1,\n",
    "    \"num_episodes\" : 300,\n",
    "    # OpenAI Gym environments allow for a timestep limit timeout, causing episodes to end after \n",
    "    # some number of timesteps. \n",
    "    \"timeout\" : 1000\n",
    "}\n",
    "\n",
    "# Environment parameters\n",
    "environment_parameters = {}\n",
    "\n",
    "current_env = Landingvehicle\n",
    "\n",
    "# Agent parameters\n",
    "agent_parameters = {\n",
    "    'network_config': {\n",
    "        'state_dim': 8,\n",
    "        'num_hidden_units': 256,\n",
    "        'num_actions': 4\n",
    "    },\n",
    "    'optimizer_config': {\n",
    "        'step_size': 1e-3,\n",
    "        'beta_m': 0.9, \n",
    "        'beta_v': 0.999,\n",
    "        'epsilon': 1e-8\n",
    "    },\n",
    "    'replay_buffer_size': 50000,\n",
    "    'minibatch_sz': 8,\n",
    "    'num_replay_updates_per_step': 4,\n",
    "    'gamma': 0.99,\n",
    "    'tau': 0.001\n",
    "}\n",
    "current_agent = Agent\n",
    "\n",
    "# run experiment\n",
    "run_experiment(current_env, current_agent, environment_parameters, agent_parameters, experiment_parameters)\n",
    "plot_result([\"expected_sarsa_agent\", \"random_agent\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div align=\"middle\">\n",
       "<video width=\"80%\" controls>\n",
       "      <source src=\"ImplementYourAgent.mp4\" type=\"video/mp4\">\n",
       "</video></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<div align=\"middle\">\n",
    "<video width=\"80%\" controls>\n",
    "      <source src=\"Landingvehicle.mp4\" type=\"video/mp4\">\n",
    "</video></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
